{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_uBJeo7lzvM"
   },
   "source": [
    "# Notebook Structure\n",
    "\n",
    "1. Import necessary dependencies\n",
    "2. Define the Utility function to analyze text\n",
    "3. Create the dataset\n",
    "4. Execute the utility function and visualize the results\n",
    "5. Create the text corpus\n",
    "6. Execute the utility function and visualize the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDeD813zGTww"
   },
   "source": [
    "# 1. Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sW1FCz06FhJ5",
    "outputId": "932d274a-4bc4-44b8-c6c1-a19da0e83648"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import re\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVBy940fGhhY"
   },
   "source": [
    "# 2. Define the Utility function to analyze text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iroMxh1YBFTv"
   },
   "source": [
    "### A. TTR Definition\n",
    "\n",
    "TTR: Type-Token Ratio\n",
    "\n",
    "TTR stands for Type-Token Ratio. It's a measure of lexical diversity in a text. Here's what the terms mean:\n",
    "\n",
    "* Token: Every single word in the text. If a word appears multiple times, each appearance is counted as a separate token.\n",
    "* Type: The unique words in the text. Repeated words are counted only once.\n",
    "\n",
    "TTR is calculated by dividing the number of unique words (types) by the total number of words (tokens):\n",
    "\n",
    "TTR = (Number of Types) / (Number of Tokens)\n",
    "\n",
    "How TTR is Useful\n",
    "\n",
    "* TTR helps us understand the variety of words used in a text. A higher TTR indicates that a text uses a greater variety of words, suggesting richer lexical diversity. Here's how it's useful:\n",
    "* Comparing Texts: TTR can be used to compare the lexical diversity of different texts. For example, you could compare the diversity of vocabulary in different essays by the same author, or compare the vocabulary in different genres of writing.\n",
    "* Developmental Analysis: In language acquisition research, TTR can be used to study how a person's vocabulary develops over time. A child's TTR is expected to increase as they learn more words.\n",
    "* Text Complexity: TTR can provide insights into the complexity of a text. A text with a high TTR might be considered more complex because it uses a wider range of vocabulary.\n",
    "* Authorship Attribution: TTR can be one of the metrics used in authorship attribution studies, where researchers try to identify the author of a text based on their writing style.\n",
    "* Simplification Assessment: TTR can be used to assess the effect of text simplification.  A simplified text might have a lower TTR than the original text.\n",
    "\n",
    "Limitations of TTR\n",
    "\n",
    "TTR is sensitive to text length. As a text gets longer, the TTR tends to decrease because there's a higher chance of words being repeated. A very long text will likely have a lower TTR than a very short text, even if both texts have the same level of diversity. Because of this, TTR is most useful when comparing texts of similar length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eOLAwxC_Gga3"
   },
   "outputs": [],
   "source": [
    "def calculate_ttr(text):\n",
    "    \"\"\"\n",
    "    Calculates the Type-Token Ratio (TTR) of a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        float: The Type-Token Ratio (TTR). Returns 0 if no tokens are found.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0.0  # Handle empty text case\n",
    "    tokens = word_tokenize(text)\n",
    "    types = set(tokens)\n",
    "    return len(types) / len(tokens) if tokens else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDGyRg2JCBG0"
   },
   "source": [
    "### B. Mattr definition\n",
    "\n",
    "MATTR: Moving Average Type-Token Ratio\n",
    "\n",
    "MATTR stands for Moving Average Type-Token Ratio. It's a measure of lexical diversity that addresses the limitations of the basic Type-Token Ratio (TTR).  Remember that TTR is affected by text length, generally decreasing as the text gets longer.  MATTR aims to provide a more stable measure of lexical diversity, regardless of text length.\n",
    "\n",
    "Here's how MATTR is calculated:\n",
    "\n",
    "* Choose a Window Size: A common window size is 50 words, but this can be adjusted.\n",
    "* Slide the Window: A \"window\" of the chosen size is moved across the text, one word at a time.\n",
    "* Calculate TTR for Each Window: For each position of the window, the TTR is calculated within that window.\n",
    "* Average the TTRs: The average of all the TTR values calculated in step 3 is the MATTR score.\n",
    "\n",
    "How MATTR is Useful\n",
    "\n",
    "MATTR provides a more reliable measure of lexical diversity than TTR, especially when comparing texts of different lengths. Here's why it's useful:\n",
    "\n",
    "* Comparison of Texts of Different Lengths: MATTR allows for more meaningful comparisons of lexical diversity across texts of varying lengths.  Because it averages TTR over smaller, fixed-size windows, it's less sensitive to the overall length of the text.\n",
    "* More Stable Measure: MATTR is considered a more stable measure of lexical diversity.  It reduces the impact of text length on the measurement.\n",
    "* Language Development Research: In studies of language acquisition, MATTR can be used to track changes in lexical diversity in a child's speech or writing over time, even if the length of their utterances or writing samples varies.\n",
    "* Authorship Attribution: Like TTR, MATTR can be used as a feature in authorship attribution studies.\n",
    "* Text Complexity Analysis: MATTR can provide a more accurate reflection of the lexical richness of a text, contributing to a better understanding of its complexity.\n",
    "* Assessment of Writing Quality: MATTR can be used to assess the lexical variety in someone's writing.\n",
    "\n",
    "In summary, MATTR is a valuable tool for analyzing lexical diversity because it provides a more consistent and length-independent measure compared to the traditional Type-Token Ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SudpdQtCY1cb"
   },
   "outputs": [],
   "source": [
    "def calculate_mattr(text, window_size=50):\n",
    "    \"\"\"\n",
    "    Calculates the Moving Average Type-Token Ratio (MATTR) of a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "        window_size (int, optional): The size of the moving window. Defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "        float: The Moving Average Type-Token Ratio (MATTR). Returns 0 if text\n",
    "               is shorter than the window size.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "    tokens = word_tokenize(text)\n",
    "    if len(tokens) < window_size:\n",
    "        return 0.0  # Handle text shorter than window size\n",
    "    ttr_values = []\n",
    "    for i in range(len(tokens) - window_size + 1):\n",
    "        window_text = tokens[i:i + window_size]\n",
    "        ttr_values.append(calculate_ttr(\" \".join(window_text)))\n",
    "    return sum(ttr_values) / len(ttr_values) if ttr_values else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb9NEKGWHyg8"
   },
   "source": [
    "### C. flesch_kincaid_reading_ease definition\n",
    "\n",
    "\n",
    "The Flesch-Kincaid Reading Ease test is a formula that calculates how easy a piece of text is to understand. It uses mathematical formulas to assess readability based on two main factors:\n",
    "\n",
    "* Average sentence length: Longer sentences are generally harder to read than shorter ones.\n",
    "* Average number of syllables per word: Words with more syllables are usually more complex.\n",
    "* The formula produces a score on a scale from 0 to 100. Higher scores indicate that the text is easier to read.\n",
    "\n",
    "How it Works\n",
    "\n",
    "The Flesch-Kincaid formula is as follows:\n",
    "\n",
    "Reading Ease = 206.835 - 1.015 * (average sentence length) - 84.6 * (average syllables per word)\n",
    "\n",
    "How to Interpret the Score\n",
    "\n",
    "Here's a general guideline for interpreting Flesch-Kincaid Reading Ease scores:\n",
    "\n",
    "* 90-100: Very easy to read. Suitable for elementary school students.\n",
    "* 80-89: Easy to read. Conversational English for consumers.\n",
    "* 70-79: Fairly easy to read.\n",
    "* 60-69: Standard reading difficulty.\n",
    "* 50-59: Fairly difficult to read.\n",
    "* 30-49: Difficult to read. Suitable for college students.\n",
    "* Below 30: Very difficult to read. Best understood by university graduates.\n",
    "\n",
    "How is it Useful?\n",
    "\n",
    "The Flesch-Kincaid Reading Ease test is widely used in various fields to ensure that written materials are accessible to the intended audience. Here are some key applications:\n",
    "\n",
    "* Education: Teachers use it to select reading materials that are appropriate for their students' reading levels.\n",
    "* Business: Companies use it to write clear and concise documents, such as user manuals, reports, and marketing materials.\n",
    "* Government: Agencies use it to create documents that are easy for the public to understand.\n",
    "* Journalism: Journalists use it to write articles that are accessible to a broad audience.\n",
    "* Technical Writing: Technical writers use it to create documentation that is easy for users to follow.\n",
    "* Healthcare: Medical professionals use it to create patient education materials that are easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "p5BYvfIQ9rsw"
   },
   "outputs": [],
   "source": [
    "def calculate_flesch_kincaid_reading_ease(text):\n",
    "    \"\"\"\n",
    "    Calculates the Flesch-Kincaid Reading Ease score of a given text.\n",
    "    Higher scores indicate easier readability.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        float: The Flesch-Kincaid Reading Ease score. Returns 0 if there are\n",
    "                no sentences or words.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len(words)\n",
    "\n",
    "    if num_sentences == 0 or num_words == 0:\n",
    "        return 0.0\n",
    "\n",
    "    num_syllables = 0\n",
    "    for word in words:\n",
    "        # A basic syllable counting heuristic (more robust)\n",
    "        vowels = 'aeiouy'\n",
    "        word = word.lower()\n",
    "        count = 0\n",
    "        if word[0] in vowels:\n",
    "            count += 1\n",
    "        for i in range(1, len(word)):\n",
    "            if word[i] in vowels and word[i-1] not in vowels:\n",
    "                count += 1\n",
    "        if word.endswith('e'):\n",
    "            count -= 1\n",
    "        if count == 0:\n",
    "            count = 1\n",
    "        num_syllables += count\n",
    "\n",
    "    average_sentence_length = num_words / num_sentences\n",
    "    average_syllables_per_word = num_syllables / num_words\n",
    "\n",
    "    # Formula for Flesch-Kincaid Reading Ease\n",
    "    score = 206.835 - 1.015 * average_sentence_length - 84.6 * average_syllables_per_word\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_A7l3OjJYzD"
   },
   "source": [
    "### D. Dale-Chall Readability Definition\n",
    "\n",
    "The Dale-Chall Readability Formula is another popular readability test used to assess the difficulty of a piece of text.  Unlike some other tests, it focuses on the use of familiar words. It compares the words in a text to a list of approximately 3,000 commonly used English words.\n",
    "\n",
    "How it Works\n",
    "\n",
    "The Dale-Chall formula calculates readability based on two factors:\n",
    "\n",
    "* Percentage of unfamiliar words: The percentage of words in the text that are not on the Dale-Chall list of familiar words.\n",
    "* Average sentence length: Similar to other readability tests, this formula considers that shorter sentences are generally easier to understand.\n",
    "\n",
    "The formula is as follows:\n",
    "\n",
    "Raw Score = 0.1579 * (Percentage of unfamiliar words) + 0.0496 * (Average sentence length)\n",
    "\n",
    "Adjusted Score = Raw Score + 3.6365\n",
    "\n",
    "If the percentage of unfamiliar words is greater than 5%, the following correction formula is used:\n",
    "\n",
    "Adjusted Score = Raw Score + 3.6365 + 0.1 * [(Percentage of unfamiliar words) ^ 2]\n",
    "\n",
    "How to Interpret the Score\n",
    "\n",
    "The Dale-Chall score corresponds to U.S. grade levels, making it easy to understand the reading difficulty:\n",
    "\n",
    "* 10-12+: College graduate\n",
    "* 13-16: College\n",
    "* 11-12: 11th to 12th grade\n",
    "* 9-10: 9th to 10th grade\n",
    "* 7-8: 7th to 8th grade\n",
    "* 5-6: 5th to 6th grade\n",
    "* 4: 4th grade\n",
    "* 1-3: 3rd grade and below\n",
    "\n",
    "How is it Useful?\n",
    "\n",
    "The Dale-Chall Readability Formula is useful in many situations where it's important to ensure that text is easy to understand:\n",
    "\n",
    "* Education: Teachers use it to select appropriate reading materials for students at different grade levels.\n",
    "* Publishing: Editors use it to assess the readability of books and articles.\n",
    "* Business: Companies use it to create clear and concise documents for customers and employees.\n",
    "* Government: Government agencies use it to write documents that are accessible to the general public.\n",
    "* Healthcare: Healthcare providers use it to create patient education materials that are easy to understand.\n",
    "* Legal: Legal professionals can use it to assess the readability of contracts and other legal documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7XTTa3fA9zHH"
   },
   "outputs": [],
   "source": [
    "def calculate_dale_chall_readability_score(text):\n",
    "    \"\"\"\n",
    "    Calculates the Dale-Chall Readability Score of a given text.\n",
    "    Lower scores indicate easier readability.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        float: The Dale-Chall Readability Score. Returns 0 if no words found.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return 0.0\n",
    "\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    num_sentences = len(sentences)\n",
    "    num_words = len(words)\n",
    "\n",
    "    if num_words == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Dale-Chall list (simplified for demonstration)\n",
    "    dale_chall_easy_words = set([\n",
    "        'a', 'about', 'above', 'after', 'again', 'all', 'always', 'and', 'an',\n",
    "        'another', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "        'below', 'between', 'big', 'but', 'by', 'call', 'can', 'come', 'day',\n",
    "        'do', 'down', 'eat', 'find', 'first', 'for', 'from', 'get', 'give', 'go',\n",
    "        'good', 'have', 'he', 'her', 'here', 'him', 'his', 'how', 'I', 'if', 'in',\n",
    "        'into', 'is', 'it', 'its', 'just', 'know', 'like', 'little', 'look', 'make',\n",
    "        'many', 'me', 'more', 'my', 'no', 'not', 'now', 'of', 'on', 'one', 'or',\n",
    "        'other', 'out', 'see', 'she', 'so', 'some', 'that', 'the', 'their', 'them',\n",
    "        'then', 'there', 'they', 'this', 'to', 'up', 'was', 'we', 'what', 'when',\n",
    "        'where', 'who', 'will', 'with', 'you', 'your'\n",
    "    ])  # A very simplified list.  The actual Dale-Chall list has thousands.\n",
    "\n",
    "    difficult_word_count = 0\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in dale_chall_easy_words:\n",
    "            difficult_word_count += 1\n",
    "\n",
    "    percentage_difficult_words = (difficult_word_count / num_words) * 100\n",
    "    average_sentence_length = num_words / num_sentences\n",
    "\n",
    "    # Dale-Chall Formula\n",
    "    raw_score = 0.1579 * percentage_difficult_words + 0.0496 * average_sentence_length\n",
    "    if percentage_difficult_words > 5: #Correction factor\n",
    "        raw_score += 3.6365\n",
    "    return raw_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xwUm0V6u97FA"
   },
   "outputs": [],
   "source": [
    "def analyze_text_lexical_diversity_and_complexity(text):\n",
    "    \"\"\"\n",
    "    Performs a univariate analysis of text lexical diversity and complexity.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics:\n",
    "            - TTR: Type-Token Ratio\n",
    "            - MATTR: Moving Average Type-Token Ratio\n",
    "            - Flesch-Kincaid Reading Ease\n",
    "            - Dale-Chall Readability Score\n",
    "    \"\"\"\n",
    "    analysis = {}\n",
    "    analysis['TTR'] = calculate_ttr(text)\n",
    "    analysis['MATTR'] = calculate_mattr(text)\n",
    "    analysis['Flesch-Kincaid Reading Ease'] = calculate_flesch_kincaid_reading_ease(text)\n",
    "    analysis['Dale-Chall Readability Score'] = calculate_dale_chall_readability_score(text)\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rrcLEBdZBxJ"
   },
   "source": [
    "# 3. Create the text corpus and execute the utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AqfayOQ5-Bt9"
   },
   "outputs": [],
   "source": [
    "# Example usage with a sample text\n",
    "sample_text = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog. The quick brown fox jumps over the lazy dog.\n",
    "The quick brown fox jumps over the lazy dog. Is this sentence complex?\n",
    "This is a simple sentence.\n",
    "A very long sentence with many, many words, and lots of commas, that just keeps going and going, and going.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LYIbo5W9-IXC"
   },
   "outputs": [],
   "source": [
    " analysis_results = analyze_text_lexical_diversity_and_complexity(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K57jYdvx-iIk",
    "outputId": "4207c7dd-2e7f-47f1-f5e4-7e40fbd76908"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TTR': 0.5151515151515151,\n",
       " 'MATTR': 0.6235294117647058,\n",
       " 'Flesch-Kincaid Reading Ease': 93.12454545454547,\n",
       " 'Dale-Chall Readability Score': 14.94800909090909}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOc9DmH9aNUB"
   },
   "source": [
    "### Interpretation of the analysis_result\n",
    "\n",
    "TTR (Type-Token Ratio): 0.515\n",
    "\n",
    "* Interpretation: A TTR of 0.515 means that 51.5% of the words in your text are unique.\n",
    "* In simpler terms: The text has a moderate level of lexical diversity. A higher TTR would suggest more variety in word choice, while a lower TTR would suggest more repetition.\n",
    "\n",
    "MATTR (Moving Average Type-Token Ratio): 0.624\n",
    "\n",
    "* Interpretation: An MATTR of 0.624 indicates that, on average, within a set window of words, 62.4% of the words are unique.\n",
    "* In simpler terms: This metric attempts to correct for the effect of text length on TTR.  It suggests a slightly higher lexical diversity than the raw TTR, implying that the diversity is fairly consistent across different sections of the text.\n",
    "\n",
    "Flesch-Kincaid Reading Ease: 93.12\n",
    "\n",
    "* Interpretation: A score of 93.12 suggests that the text is very easy to read.\n",
    "* In simpler terms: The text is likely understandable by a wide audience, including those with an elementary school education level. Higher scores indicate easier readability.\n",
    "\n",
    "Dale-Chall Readability Score: 14.95\n",
    "\n",
    "* Interpretation: A Dale-Chall score of 14.95 suggests the text is quite difficult to read.\n",
    "* In simpler terms: This score corresponds to text that is appropriate for college graduates.  The Dale-Chall formula uses a list of common words, so a higher score indicates a greater proportion of less common vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X00zEost-2mP"
   },
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "The sun dipped below the horizon, painting the sky with hues of orange, purple, and gold.\n",
    "A gentle breeze rustled through the leaves of the ancient oak tree, carrying the sweet scent of wildflowers.\n",
    "In the distance, the faint sound of a river flowed, a soothing melody to accompany the tranquil evening.\n",
    "As twilight descended, the first stars began to twinkle, their light reflecting in the still waters of the nearby lake.\n",
    "A lone owl hooted softly, its call echoing through the peaceful forest.  The world seemed to pause, suspended in a moment of quiet beauty.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kounaO4ONp9W",
    "outputId": "5623f702-5ba7-4b68-e47b-d6ca5ce51d0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TTR': 0.6637168141592921,\n",
       " 'MATTR': 0.7378124999999996,\n",
       " 'Flesch-Kincaid Reading Ease': 70.92624631268438,\n",
       " 'Dale-Chall Readability Score': 14.910987315634218}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_results = analyze_text_lexical_diversity_and_complexity(sample_text)\n",
    "analysis_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0MGqIE4a04N"
   },
   "source": [
    "### Interpretation of analysis_results\n",
    "\n",
    "TTR (Type-Token Ratio): 0.664\n",
    "\n",
    "* Interpretation: A TTR of 0.664 means that 66.4% of the words in your text are unique.\n",
    "* In simpler terms: The text has a moderately high level of lexical diversity. This suggests a good variety in word choice, indicating that the author uses a relatively rich vocabulary and avoids excessive repetition. Compared to the previous text (TTR of 0.515), this text demonstrates greater lexical variety.\n",
    "\n",
    "MATTR (Moving Average Type-Token Ratio): 0.738\n",
    "\n",
    "* Interpretation: An MATTR of 0.738 indicates that, on average, within a set window of words, 73.8% of the words are unique.\n",
    "* In simpler terms: This metric corrects for text length and confirms the lexical diversity observed in the TTR. The MATTR is higher than the TTR, suggesting that the diversity is consistent across different sections of the text. This text also has a higher MATTR than the previous text (0.624), reinforcing the observation of higher lexical diversity.\n",
    "\n",
    "Flesch-Kincaid Reading Ease: 70.93\n",
    "\n",
    "* Interpretation: A score of 70.93 suggests that the text is fairly easy to read.\n",
    "* In simpler terms: The text is likely understandable by a general audience, including those with a 7th to 8th-grade reading level. This text is slightly more challenging than the previous one (93.12), but still considered easy to read.\n",
    "\n",
    "Dale-Chall Readability Score: 14.91\n",
    "\n",
    "* Interpretation: A Dale-Chall score of 14.91 suggests that the text is quite difficult to read.\n",
    "* In simpler terms: This score indicates that the text is best understood by college graduates. The Dale-Chall formula identifies the proportion of less common vocabulary, and this text, like the previous one (14.95), contains a significant amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "W_CR0BTKNw7S"
   },
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "The pervasive juxtaposition of ephemeral phenomena with the immutable constancy of existence forms the crux of philosophical discourse.\n",
    "Epistemological frameworks, predicated upon the acquisition of knowledge through empirical observation and rational introspection, often grapple with the inherent limitations of human perception.\n",
    "Furthermore, the ontological implications of subjective experience, particularly in the context of consciousness and self-awareness, remain a subject of intense debate among cognitive scientists and philosophers alike.\n",
    "The intricate interplay between linguistic structures and cognitive processes, as elucidated by advancements in psycholinguistics, reveals the profound influence of language on shaping our understanding of reality.\n",
    "Consequently, a holistic comprehension of the human condition necessitates a multidisciplinary approach, integrating insights from diverse fields such as neuroscience, anthropology, and sociology.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSLNfyLNXIg3",
    "outputId": "110059a4-d89f-498c-a345-2db76a431a99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TTR': 0.6791044776119403,\n",
       " 'MATTR': 0.7814117647058824,\n",
       " 'Flesch-Kincaid Reading Ease': -9.138641791044762,\n",
       " 'Dale-Chall Readability Score': 16.160182985074627}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_results = analyze_text_lexical_diversity_and_complexity(sample_text)\n",
    "analysis_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8VYxZE0XdFP"
   },
   "source": [
    "### Interpretation of analysis_results\n",
    "\n",
    "TTR (Type-Token Ratio): 0.679\n",
    "\n",
    "* Interpretation: A TTR of 0.679 means that 67.9% of the words in the text are unique.\n",
    "* In simpler terms: The text exhibits a moderately high level of lexical diversity. This suggests a good variety in word choice, indicating that the author uses a relatively rich vocabulary and avoids excessive repetition.\n",
    "\n",
    "MATTR (Moving Average Type-Token Ratio): 0.781\n",
    "\n",
    "* Interpretation: An MATTR of 0.781 indicates that, on average, within a set window of words, 78.1% of the words are unique.\n",
    "* In simpler terms: This metric corrects for text length and confirms the lexical diversity observed in the TTR. The MATTR is higher than the TTR, suggesting that the diversity is consistent across different sections of the text.\n",
    "\n",
    "Flesch-Kincaid Reading Ease: -9.14\n",
    "\n",
    "* Interpretation: A score of -9.14 suggests that the text is extremely difficult to read.\n",
    "* In simpler terms: The text is very challenging to understand, likely requiring a college graduate level of education. Negative scores indicate very complex text.\n",
    "\n",
    "Dale-Chall Readability Score: 16.16\n",
    "\n",
    "* Interpretation: A Dale-Chall score of 16.16 suggests that the text is very difficult to read.\n",
    "* In simpler terms: This score indicates that the text is best understood by those with postgraduate or professional level education. The Dale-Chall formula identifies the proportion of less common vocabulary, and this text contains a significant amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qry-oDvzXLdE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
